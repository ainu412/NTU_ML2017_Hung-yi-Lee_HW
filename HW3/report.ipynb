{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "from utility import clean_data, plot_images\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['angry','disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap='Blues'):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized Confusion Matrix'\n",
    "        else:\n",
    "            title = 'Confusion Matrix, without Normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    # classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = clean_data('data/train.csv')\n",
    "train = train_data.feature.reshape((-1, 48, 48, 1))/255\n",
    "train_x = train[:-2000]\n",
    "train_label = train_data.label[:-2000]\n",
    "train_onehot = train_data.onehot[:-2000]\n",
    "test_x = train[-2000:]\n",
    "test_label = train_data.label[-2000:]\n",
    "test_onehot = train_data.onehot[-2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'cnn2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-9885f9d2da78>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcnn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'cnn2.h5'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdnn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'dnn2.h5'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001B[0m in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[0;32m    144\u001B[0m       h5py is not None and (\n\u001B[0;32m    145\u001B[0m           isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001B[1;32m--> 146\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mhdf5_format\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_model_from_hdf5\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcustom_objects\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcompile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    147\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    148\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstring_types\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001B[0m in \u001B[0;36mload_model_from_hdf5\u001B[1;34m(filepath, custom_objects, compile)\u001B[0m\n\u001B[0;32m    198\u001B[0m   \u001B[0mopened_new_file\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh5py\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mopened_new_file\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 200\u001B[1;33m     \u001B[0mf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mh5py\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mFile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'r'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    201\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    202\u001B[0m     \u001B[0mf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfilepath\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001B[0m\n\u001B[0;32m    406\u001B[0m                 fid = make_fid(name, mode, userblock_size,\n\u001B[0;32m    407\u001B[0m                                \u001B[0mfapl\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfcpl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmake_fcpl\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrack_order\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrack_order\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 408\u001B[1;33m                                swmr=swmr)\n\u001B[0m\u001B[0;32m    409\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    410\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlibver\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001B[0m in \u001B[0;36mmake_fid\u001B[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001B[0m\n\u001B[0;32m    171\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mswmr\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mswmr_support\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    172\u001B[0m             \u001B[0mflags\u001B[0m \u001B[1;33m|=\u001B[0m \u001B[0mh5f\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mACC_SWMR_READ\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 173\u001B[1;33m         \u001B[0mfid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mh5f\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfapl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfapl\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    174\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'r+'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    175\u001B[0m         \u001B[0mfid\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mh5f\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mh5f\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mACC_RDWR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfapl\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfapl\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mh5py\\_objects.pyx\u001B[0m in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mh5py\\_objects.pyx\u001B[0m in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mh5py\\h5f.pyx\u001B[0m in \u001B[0;36mh5py.h5f.open\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: Unable to open file (unable to open file: name = 'cnn2.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "cnn = load_model('cnn.h5')\n",
    "dnn = load_model('dnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predict = cnn.predict(test_x)\n",
    "cnn_cls = np.argmax(cnn_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_predict = dnn.predict(test_x)\n",
    "dnn_cls = np.argmax(dnn_predict, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_label, cnn_cls, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_label, dnn_cls, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cls = pd.Series(test_label, name='true_cls')[test_label!=cnn_cls]\n",
    "wrong_cls = pd.Series(cnn_cls, name='wrong_cls')[test_label!=cnn_cls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong = pd.concat([true_cls, wrong_cls], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_neu = wrong[wrong['true_cls']==4][wrong['wrong_cls']==6].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sad_neu[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(test_x[sample], test_label[sample], cnn_cls[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_saliency, overlay\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "from keras.models import load_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = load_model('cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap softmax with linear\n",
    "cnn.layers[-1].activation = activations.linear\n",
    "cnn = utils.apply_modifications(cnn)\n",
    "\n",
    "grads = visualize_saliency(cnn, -1, filter_indices=test_label[0], seed_input=test_x[0], backprop_modifier='guided')\n",
    "# Plot with 'jet' colormap to visualize as a heatmap.\n",
    "plt.imshow(grads, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(6):    \n",
    "    \n",
    "\n",
    "    f, ax = plt.subplots(1, 4)\n",
    "    ax[0].imshow(test_x[idx].reshape((48,48)), cmap='gray')\n",
    "    \n",
    "    for i, modifier in enumerate([None, 'guided', 'relu']):\n",
    "        grads = visualize_saliency(cnn, -1, filter_indices=test_label[idx], \n",
    "                                   seed_input=test_x[idx], backprop_modifier=modifier)\n",
    "        if modifier is None:\n",
    "            modifier = 'vanilla'\n",
    "        ax[i+1].set_title(modifier)    \n",
    "        ax[i+1].imshow(grads, cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_input = cnn.layers[0]\n",
    "layer_conv1 = cnn.layers[1]\n",
    "layer_conv2 = cnn.layers[5]\n",
    "layer_conv3 = cnn.layers[9]\n",
    "conv_layers = [layer_conv1, layer_conv2, layer_conv3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_conv1.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conv_weights(weights, input_channel=0):\n",
    "    # Get the lowest and highest values for the weights.\n",
    "    # This is used to correct the colour intensity across\n",
    "    # the images so they can be compared with each other.\n",
    "    w_min = np.min(weights)\n",
    "    w_max = np.max(weights)\n",
    "\n",
    "    # Number of filters used in the conv. layer.\n",
    "    num_filters = weights.shape[3]\n",
    "\n",
    "    # Number of grids to plot.\n",
    "    # Rounded-up, square-root of the number of filters.\n",
    "    num_grids = math.ceil(math.sqrt(num_filters))\n",
    "    \n",
    "    # Create figure with a grid of sub-plots.\n",
    "    fig, axes = plt.subplots(8, 8)\n",
    "\n",
    "    # Plot all the filter-weights.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only plot the valid filter-weights.\n",
    "        if i<num_filters:\n",
    "            # Get the weights for the i'th filter of the input channel.\n",
    "            # See new_conv_layer() for details on the format\n",
    "            # of this 4-dim tensor.\n",
    "            img = weights[:, :, input_channel, i]\n",
    "\n",
    "            # Plot image.\n",
    "            ax.imshow(img, vmin=w_min, vmax=w_max,\n",
    "                      interpolation='nearest', cmap='seismic')\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for conv_layer in conv_layers:\n",
    "    plot_conv_weights(conv_layer.get_weights()[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conv_output(values):\n",
    "    # Number of filters used in the conv. layer.\n",
    "    num_filters = values.shape[3]\n",
    "\n",
    "    # Number of grids to plot.\n",
    "    # Rounded-up, square-root of the number of filters.\n",
    "    num_grids = math.ceil(math.sqrt(num_filters))\n",
    "    \n",
    "    # Create figure with a grid of sub-plots.\n",
    "    fig, axes = plt.subplots(8, 8)\n",
    "\n",
    "    # Plot the output images of all the filters.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only plot the images for valid filters.\n",
    "        if i<num_filters:\n",
    "            # Get the output image of using the i'th filter.\n",
    "            img = values[0, :, :, i]\n",
    "\n",
    "            # Plot image.\n",
    "            ax.imshow(img, interpolation='nearest', cmap='Blues')\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = test_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.reshape(48,48), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_conv1 = K.function(inputs=[layer_input.input],\n",
    "                          outputs=[layer_conv1.output])\n",
    "output_conv2 = K.function(inputs=[layer_input.input],\n",
    "                          outputs=[layer_conv2.output])\n",
    "output_conv3 = K.function(inputs=[layer_input.input],\n",
    "                          outputs=[layer_conv3.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output1 = output_conv1([[image]])[0]\n",
    "layer_output2 = output_conv2([[image]])[0]\n",
    "layer_output3 = output_conv3([[image]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_conv_output(values=layer_output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conv_output(values=layer_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conv_output(values=layer_output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a loss function that maximizes the activation\n",
    "# of the nth filter of the layer considered\n",
    "layer_output = layer_conv1.output\n",
    "filter_index = 0\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "# compute the gradient of the input picture wrt this loss\n",
    "grads = K.gradients(loss, layer_input.input)[0]\n",
    "\n",
    "# normalization trick: we normalize the gradient\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([layer_input.input], [loss, grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we start from a gray image with some noise\n",
    "input_img_data = np.random.random((1, 48, 48, 1)) * 20 + 128.\n",
    "# run gradient ascent for 20 steps\n",
    "for i in range(500):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += grads_value * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(input_img_data.reshape(48,48), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter(layer_conv):\n",
    "    result = []\n",
    "    layer_output = layer_conv.output\n",
    "    for filter_index in range(64):\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "        # compute the gradient of the input picture wrt this loss\n",
    "        grads = K.gradients(loss, layer_input.input)[0]\n",
    "\n",
    "        # normalization trick: we normalize the gradient\n",
    "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "        # this function returns the loss and grads given the input picture\n",
    "        iterate = K.function([layer_input.input], [loss, grads])\n",
    "        input_img_data = np.random.random((1, 48, 48, 1)) * 20 + 128.\n",
    "        # run gradient ascent for 20 steps\n",
    "        for i in range(500):\n",
    "            loss_value, grads_value = iterate([input_img_data])\n",
    "            input_img_data += grads_value * 0.1\n",
    "        result.append(input_img_data.reshape(48,48))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filter(layer_conv):\n",
    "     # Create figure with a grid of sub-plots.\n",
    "    fig, axes = plt.subplots(8, 8)\n",
    "    img = _filter(layer_conv)\n",
    "    # Plot the output images of all the filters.\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        ax.imshow(img[i], interpolation='nearest', cmap='Blues')\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filter(layer_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filter(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filter(layer_conv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}